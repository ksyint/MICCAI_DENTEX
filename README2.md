# 법률 QA RAG 시스템

법률 및 규정 질문에 대한 RAG(Retrieval-Augmented Generation) 기반 자동 답변 시스템입니다.

## 시스템 개요

본 시스템은 하이브리드 임베딩 검색과 GPT-4o-mini를 활용하여 법률 관련 다지선다형 질문에 답변합니다.

### 주요 특징
- **하이브리드 임베딩 검색**: 질문(70%)과 선택지(30%)를 조합한 유사도 계산
- **적응형 컨텍스트 구성**: top-k 및 선택지 포함 여부를 동적으로 조정
- **반복 실험 기반 최적화**: 동일 조건에서 10회 반복 실행으로 안정성 확보

## 설치 방법

```bash
pip install -r requirements.txt
```

## 실행 방법

### 1. 데이터 준비
```bash
# data/ 디렉토리에 train.csv, dev.csv 파일 배치
data/
├── train.csv
└── dev.csv
```

### 2. 검색 인덱스 구축 및 검색 수행
```bash
python retrieve.py
```

**출력 파일**: `retrieve_results.json` (각 dev 쿼리에 대한 검색 결과)

### 3. 평가 실행
```bash
python evaluate.py
```

**설정 변경** (evaluate.py 하단):
```python
TOP_K = 12              # 검색할 문서 개수
N_ROUNDS = 10           # 반복 실험 횟수
INCLUDE_CHOICE = False  # 컨텍스트에 선택지 포함 여부
```

**출력 파일**:
- `result_top_{k}_choice_{bool}.txt`: 실험 로그
- `result_top_{k}_choice_{bool}_predictions.csv`: 최고 성능 예측 결과

## Agent System 구조

```
┌─────────────────────────────────────────────────────────────┐
│                     Query Input (Dev Set)                    │
└────────────────────────────┬────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────┐
│              Hybrid Embedding Retriever                      │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  1. Question Embedding (text-embedding-3-small)      │   │
│  │     - Query question → 1536-dim vector               │   │
│  │     - Train questions → pre-computed vectors         │   │
│  │     - Cosine similarity → Q_score                    │   │
│  └──────────────────────────────────────────────────────┘   │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  2. Choice Embedding (text-embedding-3-small)        │   │
│  │     - Query 4 choices → 4 × 1536-dim vectors         │   │
│  │     - Train 4 choices each → pre-computed vectors    │   │
│  │     - Max similarity per train × Mean → C_score      │   │
│  └──────────────────────────────────────────────────────┘   │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  3. Weighted Combination                             │   │
│  │     Final_score = 0.7 × Q_score + 0.3 × C_score      │   │
│  │     Top-K selection (K=12 optimal)                   │   │
│  └──────────────────────────────────────────────────────┘   │
└────────────────────────────┬────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────┐
│              Context Construction Module                     │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  [참고자료 1] (유사도: 0.xxxx)                        │   │
│  │  Question: ...                                        │   │
│  │  [Choice: ... ] ← Optional (INCLUDE_CHOICE=False)    │   │
│  │  Answer: ...                                          │   │
│  │                                                        │   │
│  │  [참고자료 2] ...                                     │   │
│  │  ...                                                   │   │
│  └──────────────────────────────────────────────────────┘   │
└────────────────────────────┬────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────┐
│              LLM Reasoning (GPT-4o-mini)                    │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  System: 법률 전문가 + RAG 지침                       │   │
│  │  Context: Top-K 참고자료                              │   │
│  │  Query: 질문 + 4개 선택지                            │   │
│  │  Temperature: 0 (deterministic)                       │   │
│  │  Output: 정답 번호 (1-4)                             │   │
│  └──────────────────────────────────────────────────────┘   │
└────────────────────────────┬────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────┐
│                   Answer Extraction                          │
│              Regex parsing → Index matching                  │
└─────────────────────────────────────────────────────────────┘
```

## Dev Set 벤치마크 성능

| 설정 | Top-K | Choice in Context | 평균 정확도 | 최고 정확도 | 최소 정확도 |
|------|-------|-------------------|-------------|-------------|-------------|
| No RAG | 0 | N/A | **46.16%** | 47.60% | 45.20% |
| RAG | 7 | False | 46.60% | 47.60% | 45.60% |
| RAG | 7 | True | **48.24%** | 49.20% | 47.20% |
| RAG | 10 | False | 46.52% | 47.20% | 45.20% |
| RAG | 10 | True | 46.92% | 47.60% | 46.40% |
| RAG | 12 | False | **48.48%** | 50.00% | 47.20% |
| RAG | 12 | True | 45.36% | 46.40% | 44.80% |
| RAG | 13 | False | **48.56%** | 49.60% | 46.40% |
| RAG | 13 | True | 46.84% | 48.40% | 46.00% |
| RAG | 14 | False | **48.72%** | 50.00% ★ | 48.00% ★ |
| RAG | 14 | True | 48.60% | 49.60% | 47.60% |

### 최적 설정
- **Configuration**: Top-K=14, Choice_in_Context=False
- **Best Accuracy**: **50.00%** (125/250)
- **Average Accuracy**: **48.72%** (k=14, no choice)
- **Minimum Accuracy**: **48.00%** (k=14, no choice) ← 가장 안정적

### 성능 향상
- Baseline (No RAG): 46.16%
- Best RAG: 48.72% (k=14, no choice)
- **절대 향상**: +2.56%p
- **상대 향상**: +5.5%

### 안정성 분석
- Top-14 설정의 성능 범위: 48.00% ~ 50.00%
- 표준편차: 0.67%p
- **최소 성능도 baseline을 1.84%p 상회** → 매우 안정적

## 핵심 발견사항

1. **하이브리드 검색의 효과**: 질문만 사용하는 것보다 선택지 정보를 함께 활용할 때 검색 품질 향상
2. **컨텍스트 길이의 역설**: k≥12일 때 선택지를 컨텍스트에 포함하지 않는 것이 더 효과적
3. **최적 k값**: 12-14개의 참고자료가 가장 균형잡힌 성능 제공

## 환경 요구사항

- Python 3.8+
- OpenAI API Key (text-embedding-3-small, gpt-4o-mini 접근 권한)
- 메모리: 최소 4GB RAM (임베딩 처리 시)

## 라이선스

본 프로젝트는 교육 및 연구 목적으로 제공됩니다.
